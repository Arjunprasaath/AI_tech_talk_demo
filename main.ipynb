{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import moviepy.editor\n",
    "from pytube import YouTube\n",
    "\n",
    "with open('key.txt', 'r') as f:\n",
    "    key = f.read()\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download video from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/arjunsmac/Documents/CODING/python_code/AI Tech talk REC/What is Happening with Samsungs Camera.3gpp'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTube('https://youtu.be/1afpDuTb-P0').streams.first().download('/Users/arjunsmac/Documents/CODING/python_code/AI Tech talk REC/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract audio from the downloaded video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video = moviepy.editor.VideoFileClip(\"video.3gpp\")\n",
    "audio = video.audio\n",
    "audio.write_audiofile(\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating transcript using Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file= open(\"audio.mp3\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Well, I was wrong. So time to own it. What is a photo? What is a photo? That's a real question that I'm not sure has a straightforward answer anymore in this age of smartphone cameras that we live in. Case in point, the latest questions with Samsung. Now this is a bit of a part two to a video I've already made called what's happening with the iPhone's camera. But that's about the broader topic of smartphone cameras and computational photography. And the more interesting thing, which is taking pictures of people. I'll link that below the like button. This one is more of a side quest of the specific edge case of phones with zoom at night, zooming all the way in and taking pictures of the moon. So first I'd like to admit I was wrong. I made a short about a month or so ago. I'm not gonna delete it, but it's of me zooming all the way in to 100X space zoom on the Galaxy S23 Ultra and taking a picture of the moon that looks really impressive. And I said, I guess it's not doing the AI fakery that Huawei got caught doing years ago. But to be fair, that's not what I should have done. What I should have done is actually tested it, done some AB experiment type stuff. I should have tested it and ran an experiment like Reddit user iBreakPhotos actually did this past weekend. And well, as you can probably tell, the findings were kind of interesting. So let me show you. So basically when you point a camera in the sky and zoom all the way into the moon, it recognizes the moon as a subject of the photo and it locks the electronic stabilization on the target, sets the focus distance to infinity and fires up a detail improvement engine to make the moon look much clearer than it would normally be. The easiest way to prove this is exactly how the Reddit experiment went. If you load up a full resolution picture of the moon and point the camera at it, it triggers all these systems and the same set of processes. But then if you pull up a blurred photo of the moon with many of these details obscured and do the exact same thing, zoom all the way in, point the camera at it, what happens is it still runs all the same improvements and processes because it recognizes a moon. And then it turns out the camera will spit out a clearer, more detailed photo of the moon with all sorts of sharp detail that wasn't even in the source image. It feels weird. It feels fake. Like the fact that it's getting a bunch of detail out of the shot that wasn't in front of your camera in the first place just feels wrong. To be fair, it's not exactly doing what Huawei was accused of doing. Huawei is accused of doing this brute force like overlay fakery where, okay, you point there's at the moon, it recognizes the moon, and then it just drops an overlay on top of the moon to get that detail out of nowhere. Because that's what our brains assumed that was happening. Huawei denies this. But to be fair, this would work with moon photography because the moon, as you know, is tidally locked and the same side always faces earth. So the overlay would always be perfectly accurate. But what's actually happening with Samsung's is a little more complicated than that. So like I said, you point that camera at the moon. Once you get past 25X zoom, if the sky is clear enough and the moon is recognized as the target, the camera app turns the exposure all the way down to take it from a glowing white orb to an actually somewhat detailed object. Then like I said, it sets the focus to its furthest distance. It locks the electronic stabilization on the target object. And then it runs a series of noise reduction and detail enhancement processes that basically AI sharpen what you see in the viewfinder towards what it knows the moon is supposed to look like. So yes, everyone who has this phone that takes a picture of the same moon is gonna get like basically the same looking image at 100X. But if it's got some color to it, if the moon is red to you, then it will keep that intact. If something flies in front of it, theoretically that should stay intact. And then it matches the phase of the moon. So it'll work on any phase, half moon, gibbous, crescent, whatever, that's fine too. Now you might be asking, guys, how do you know all of this? Well, one, because we actually ran these experiments on pictures of the moon like the Reddit user did, but also two, there is an entire post on a Samsung forum. There's a Samsung community forum and there's a post that details all of this, like how it works, what phones it works on and the step-by-step process that it goes through when it recognizes the moon in the sky. It's in Korean, so you may have to run it through translate to read it yourself, but yeah, it's out there. So you can disable this feature just by turning off the scene optimizer setting in the camera app, whose description right now on my phone says it makes dark scenes look brighter, food look tastier and landscapes look more vivid. They should also add, also makes the moon look extra crispy and bright and detailed so you can flex on all your iPhone friends who don't have 100X zoom. But to me, this is just one of many types of photos that our smartphones are already editing for us. I've said it in a previous video, the stuff that comes out of a smartphone camera isn't so much reality, as much as it's this computer's interpretation of what it thinks you'd like reality to look like. So of course, anytime there's a full moon, everyone with an S23 Ultra is super tempted to zoom all the way in and take the same picture of the moon because it looks super impressive and it's visually cool, but also then the headlines are gonna say, that's kind of fake. But these phones will continue to recognize a landscape and turn the grass more green, or recognize a wide angle shot with the sky in it and turn the sky more blue. It'll recognize a photo of food and boost the most saturated colors. Of course, the one with the moon is the most visually impressive and easy to pay attention to, but what is a photo? Moon mode magic makes the media mad, but many more manipulated megapixels have their merit. Thanks for watching. Catch you guys in the next one. Peace.\"\n",
      "}\n",
      "6173\n"
     ]
    }
   ],
   "source": [
    "print(transcript)\n",
    "print(len(transcript['text']))\n",
    "text = transcript['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating key points from transcript using GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo-16k\",\n",
    "  messages = [\n",
    "      {\"role\" : \"system\", \n",
    "       \"content\" : f\"Pick out the key point mentioned in the transcript given. Break each sentence into a new line. Transcript = {text}\"},\n",
    "  ],\n",
    "  temperature = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key point mentioned in the transcript is that smartphone cameras, specifically Samsung's, have a feature that enhances and edits photos of the moon to make them appear clearer and more detailed than they actually are. This feature recognizes the moon as the subject of the photo and applies various processes to improve the image. The transcript also discusses how smartphone cameras in general edit and enhance photos to create a desired interpretation of reality.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "with open('key_points.txt','+a') as f:\n",
    "    f.write(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
